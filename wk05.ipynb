{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ef89c0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2960721161.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    The key factor that determines whether an idea can be examined and tested statistically is whether the idea is quantifiable and measurable.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "The key factor that determines whether an idea can be examined and tested statistically is whether the idea is quantifiable and measurable. \n",
    "A good null hypothesis has the following characteristics: testable, clear and specific,assumes no effect and falsifiable.\n",
    "    The null hypothesis that there is no effect or no difference. It represents the status quo or baseline assumption while \n",
    "    alternative Hypothesis represents the presence of an effect or a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc41203c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (973153346.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Although we use the sample data for our calculations, our conclusions are for the population and not just for the sample itself.\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Although we use the sample data for our calculations, our conclusions are for the population and not just for the sample itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba7438c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2231104770.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    When we calculate the p-value, we assume that the null hypothesis is true, meaning that we assume that there are no significant effects or differences under this hypothesis. The purpose of this was to assess how likely the data we observed would be if this hypothesis were true.\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "When we calculate the p-value, we assume that the null hypothesis is true, meaning that we assume that there are no significant effects\n",
    "or differences under this hypothesis. The purpose of this was to assess how likely the data we observed would be if this hypothesis were true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54224e78",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (582551729.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    When p-value is small, it represents that the current data results do not match the predictions of the null hypothesis,\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "When p-value is small, it represents that the current data results do not match the predictions of the null hypothesis, \n",
    "which makes the null hypothesis less plausible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89664b67",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 2) (2783652009.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    According to the null hypothesis, assuming the direction of each couple's head tilt can be seen as a \"50/50 coin toss.\"\u001b[0m\n\u001b[0m                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 2)\n"
     ]
    }
   ],
   "source": [
    "First, we suppose that there is no preference for the direction of the head tilt when kissing. \n",
    "According to the null hypothesis, assuming the direction of each couple's head tilt can be seen as a \"50/50 coin toss.\"\n",
    "Lastly，We counted how many times in the simulation the number of right-leaning couples was greater than\n",
    "or equal to the 80 couples we actually observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b225559",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (78994117.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    A smaller p-value does not unequivocally prove that the null hypothesis is false. The P-value simply indicates how likely the data\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "A smaller p-value does not unequivocally prove that the null hypothesis is false. The P-value simply indicates how likely the data \n",
    "is to be observed if the null hypothesis is true. A smaller P-value indicates that the data does not match the null hypothesis,\n",
    "but it is not 100% certain that the null hypothesis is wrong.\n",
    "In general, a P-value below 0.05 is considered to provide strong evidence against the null hypothesis,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f25e082d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PatientID' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mPatientID\u001b[49m,Age,Gender,InitialHealthScore,FinalHealthScore\n\u001b[1;32m      2\u001b[0m \u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m45\u001b[39m,M,\u001b[38;5;241m84\u001b[39m,\u001b[38;5;241m86\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m34\u001b[39m,F,\u001b[38;5;241m78\u001b[39m,\u001b[38;5;241m86\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PatientID' is not defined"
     ]
    }
   ],
   "source": [
    "PatientID,Age,Gender,InitialHealthScore,FinalHealthScore\n",
    "1,45,M,84,86\n",
    "2,34,F,78,86\n",
    "3,29,M,83,80\n",
    "4,52,F,81,86\n",
    "5,37,M,81,84\n",
    "6,41,F,80,86\n",
    "7,33,M,79,86\n",
    "8,48,F,85,82\n",
    "9,26,M,76,83\n",
    "10,39,F,83,84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c1de67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Bootstrap Confidence Interval for the Mean of Initial Health Score: (79.2975, 82.7025)\n",
      "95% Bootstrap Confidence Interval for the Mean of Final Health Score: (83.0, 85.5)\n",
      "95% Bootstrap Confidence Interval for the Median of Final Health Score: (83.0, 86.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Manually input the dataset as seen in the image\n",
    "data = {\n",
    "    'PatientID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Age': [45, 34, 29, 52, 37, 41, 33, 48, 26, 39],\n",
    "    'Gender': ['M', 'F', 'M', 'F', 'M', 'F', 'M', 'F', 'M', 'F'],\n",
    "    'InitialHealthScore': [84, 78, 83, 81, 81, 80, 79, 85, 76, 83],\n",
    "    'FinalHealthScore': [86, 86, 80, 86, 84, 86, 86, 82, 83, 84]\n",
    "}\n",
    "\n",
    "# Convert to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Bootstrapping function\n",
    "def bootstrap_confidence_interval(data, num_bootstrap_samples=1000, ci_level=95, statistic=np.mean):\n",
    "    \"\"\"\n",
    "    Function to compute the bootstrap confidence interval for a given statistic (default is the mean).\n",
    "    \n",
    "    Parameters:\n",
    "    - data: The data column to be bootstrapped (e.g., df['InitialHealthScore']).\n",
    "    - num_bootstrap_samples: Number of bootstrap samples (default is 1000).\n",
    "    - ci_level: The confidence level for the interval (default is 95%).\n",
    "    - statistic: The statistic to calculate for each bootstrap sample (default is np.mean).\n",
    "    \n",
    "    Returns:\n",
    "    - (lower_bound, upper_bound): The computed confidence interval.\n",
    "    \"\"\"\n",
    "    # List to store the statistic calculated from each bootstrap sample\n",
    "    bootstrap_statistics = []\n",
    "    \n",
    "    # Generate bootstrap samples and compute the statistic for each sample\n",
    "    for _ in range(num_bootstrap_samples):\n",
    "        # Generate a bootstrap sample by sampling with replacement from the original data\n",
    "        bootstrap_sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        \n",
    "        # Calculate the statistic for this bootstrap sample (e.g., mean, median, etc.)\n",
    "        bootstrap_statistics.append(statistic(bootstrap_sample))\n",
    "     # Compute the lower and upper percentiles for the confidence interval\n",
    "    lower_percentile = (100 - ci_level) / 2\n",
    "    upper_percentile = 100 - lower_percentile\n",
    "    lower_bound = np.percentile(bootstrap_statistics, lower_percentile)\n",
    "    upper_bound = np.percentile(bootstrap_statistics, upper_percentile)\n",
    "    \n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Bootstrapping for the Initial Health Score\n",
    "initial_health_ci = bootstrap_confidence_interval(df['InitialHealthScore'], num_bootstrap_samples=1000, statistic=np.mean)\n",
    "print(f\"95% Bootstrap Confidence Interval for the Mean of Initial Health Score: {initial_health_ci}\")\n",
    "\n",
    "# Bootstrapping for the Final Health Score\n",
    "final_health_ci = bootstrap_confidence_interval(df['FinalHealthScore'], num_bootstrap_samples=1000, statistic=np.mean)\n",
    "print(f\"95% Bootstrap Confidence Interval for the Mean of Final Health Score: {final_health_ci}\")\n",
    "\n",
    "# Bootstrapping for the Median of Final Health Score\n",
    "final_health_median_ci = bootstrap_confidence_interval(df['FinalHealthScore'], num_bootstrap_samples=1000, statistic=np.median)\n",
    "print(f\"95% Bootstrap Confidence Interval for the Median of Final Health Score: {final_health_median_ci}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ff8f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observed Difference in Means: 3.299999999999997\n",
      "One-Sided p-value: 0.521\n"
     ]
    }
   ],
   "source": [
    "# Observed difference in means between FinalHealthScore and InitialHealthScore\n",
    "observed_diff = df['FinalHealthScore'].mean() - df['InitialHealthScore'].mean()\n",
    "\n",
    "# Bootstrapping to generate the null distribution of differences in means\n",
    "bootstrap_diffs = []\n",
    "for _ in range(1000):\n",
    "    # Generate bootstrap samples for both Initial and Final Health Scores\n",
    "    bootstrap_initial = np.random.choice(df['InitialHealthScore'], size=len(df), replace=True)\n",
    "    bootstrap_final = np.random.choice(df['FinalHealthScore'], size=len(df), replace=True)\n",
    "    \n",
    "    # Calculate the difference in means for this bootstrap sample\n",
    "    bootstrap_diff = bootstrap_final.mean() - bootstrap_initial.mean()\n",
    "    bootstrap_diffs.append(bootstrap_diff)\n",
    "\n",
    "# Calculate the p-value (one-tailed test: FinalHealthScore > InitialHealthScore)\n",
    "# Proportion of bootstrap differences that are greater than or equal to the observed difference\n",
    "p_value = np.mean(np.array(bootstrap_diffs) >= observed_diff)\n",
    "\n",
    "print(f\"Observed Difference in Means: {observed_diff}\")\n",
    "print(f\"One-Sided p-value: {p_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71a7bf8b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1246495690.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    the primary code is about estimating confidence intervals, whereas the hypothesis testing code is about testing for differences between two groups.\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " the primary code is about estimating confidence intervals, whereas the hypothesis testing code is about testing for differences between two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5613f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0294"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "n_students = 80  \n",
    "observed_correct = 49 \n",
    "p_null = 0.5  \n",
    "\n",
    "\n",
    "n_simulations = 10000\n",
    "simulated_correct = np.random.binomial(n_students, p_null, n_simulations)\n",
    "\n",
    "\n",
    "p_value = np.mean(simulated_correct >= observed_correct)\n",
    "p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b05ec853",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:18\u001b[0;36m\u001b[0m\n\u001b[0;31m    - Formal statement: \\( H_0: p = 0.5 \\), where \\( p \\) is the true probability of students correctly identifying the order.\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "1. Problem Introduction\n",
    "\n",
    "This experiment aims to test whether STA130 students can correctly determine the order in which milk or tea was poured by taste. \n",
    "It is based on Fisher’s tea experiment, where Dr. Bristol claimed she could distinguish whether milk or tea was poured first. \n",
    "Our goal is to conduct a hypothesis test to determine if the students’ ability to judge the order exceeds random guessing.\n",
    "\n",
    "2. Relationship between this experiment and Fisher and Bristol’s original experiment\n",
    "\n",
    "Fisher’s original experiment tested whether Dr. Bristol could distinguish the order of milk and tea by taste. Bristol correctly \n",
    "identified all 8 cups. In this experiment, we use 80 STA130 students, with each tasting one cup of tea, assuming that 49 students correctly \n",
    "identify whether tea or milk was poured first. This experiment has a larger sample size and tests a more general ability, \n",
    "rather than Dr. Bristol’spersonalized skill.\n",
    "\n",
    "3. Null and Alternative Hypothesis Statements\n",
    "\n",
    "- Null Hypothesis (\\( H_0 \\)): The students do not have a better ability than random guessing to determine the order of milk or \n",
    "    tea being poured, meaning the probability of guessing correctly is 50%.\n",
    "  - Formal statement: \\( H_0: p = 0.5 \\), where \\( p \\) is the true probability of students correctly identifying the order.\n",
    "  - Informal explanation: The students’ accuracy in determining the order of milk or tea is no better than random guessing.\n",
    "\n",
    "- Alternative Hypothesis (\\( H_A \\)): The students have a higher accuracy than random guessing in determining the order of milk or tea.\n",
    "  - Formal statement: \\( H_A: p > 0.5 \\)\n",
    "\n",
    "4. Quantitative Analysis\n",
    "\n",
    "We perform a hypothesis test to evaluate the null hypothesis by examining whether the 49 correct responses out of 80 students \n",
    "could be explained by random guessing. We simulate the distribution of correct guesses under the assumption that the probability \n",
    "of guessing correctly is 0.5 (the null hypothesis). We then compute the p-value to assess whether our observed result (49 correct guesses) \n",
    "is enough to reject the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e70c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot history：https://chatgpt.com/c/67083c9c-aff8-8012-bdfd-e79041dbbae8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
